{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"linear_tb.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"rsCGpL8LOgYx","colab":{}},"source":["#%tensorflow_version 2.x  # Run this if on Colab!!\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uJQUvZVoOkP6","colab":{}},"source":["tf.__version__  # make sure it's 2.0!"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"M4ebt5aTSqTp","colab":{}},"source":["import numpy as np\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pnZB3WIzSpeD","colab":{}},"source":["# If you want to get datasets.py via google drive...\n","\n","#from google.colab import drive\n","#drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g5jdTaq_TpAw","colab":{}},"source":["# drive thing part 2\n","#os.chdir(\"drive/My Drive/Colab Notebooks\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mWi8AoMMT0K-","colab":{}},"source":["from datasets import MNISTDataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bModr9jsUIUp","colab":{}},"source":["mnist = tf.keras.datasets.mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","data = MNISTDataset(train_images.reshape([-1, 784]), train_labels, test_images.reshape([-1, 784]), test_labels, 128)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ONj3mtPOkE8I","colab":{}},"source":["train_steps = 1000\n","lr = 0.1\n","\n","W = tf.Variable(np.zeros([784, 10]).astype(np.float32))\n","b = tf.Variable(np.zeros(10, dtype=np.float32))\n","\n","# first change: set up log dir and file writer(s)\n","import time\n","logdir = os.path.join(\"logs\", \"linear\" + str(time.time()))\n","train_writer = tf.summary.create_file_writer(os.path.join(logdir, \"train\"))\n","test_writer = tf.summary.create_file_writer(os.path.join(logdir, \"test\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"r5cYJW1ZtIn-","colab":{}},"source":["for step in range(train_steps):\n","    img_batch, lbl_batch = data.next_batch()\n","    with tf.GradientTape() as tape:\n","        logits = tf.matmul(img_batch, W) + b\n","        xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n","            logits=logits, labels=lbl_batch))\n","        \n","    grads = tape.gradient(xent, [W, b])\n","    W.assign_sub(lr * grads[0])\n","    b.assign_sub(lr * grads[1])\n","    \n","    # change #2: log this stuff every time step (rather wasteful)\n","    with train_writer.as_default():\n","        tf.summary.scalar(\"loss\", xent, step=step)\n","        tf.summary.histogram(\"logits\", logits, step=step)\n","        tf.summary.histogram(\"weights\", W, step=step)\n","    \n","    if not step % 100:\n","        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n","        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch), tf.float32))\n","        \n","        # change #3: log this only once every 100 steps\n","        with train_writer.as_default():\n","            tf.summary.scalar(\"accuracy\", acc, step=step)\n","            tf.summary.image(\"input\", tf.reshape(img_batch, [-1, 28, 28, 1]), step=step)\n","            \n","        test_preds = tf.argmax(tf.matmul(data.test_data, W) + b, axis=1, output_type=tf.int32)\n","        test_acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, data.test_labels), tf.float32))\n","        with test_writer.as_default():\n","            tf.summary.scalar(\"accuracy\", test_acc, step=step)\n","        \n","        print(\"Training Loss: {} Accuracy: {}\".format(xent, acc))\n","        print(\"Test accuracy: {}\\n\".format(test_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uVvooGsLkXgb","colab":{}},"source":["# then load/run tensorboard\n","\n","%load_ext tensorboard"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3GsmSq2_tP9U","colab":{}},"source":["%tensorboard --logdir logs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7AqJenTZucoq","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}